# Fine-Tuning Guide: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ TikTok –¥–∞–Ω–Ω—ã—Ö

## üéØ –¶–µ–ª—å

–î–æ–æ–±—É—á–∏—Ç—å VideoMAE –∏ VideoLLaMA3 –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö TikTok –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤–∏—Ä—É—Å–Ω–æ—Å—Ç–∏.

## üìä –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã

### 1. TikTok-10M ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (–û—Å–Ω–æ–≤–Ω–æ–π)

**HuggingFace:** `The-data-company/TikTok-10M`

**–°–æ–¥–µ—Ä–∂–∏—Ç:**
- 6.65 –º–ª–Ω TikTok –≤–∏–¥–µ–æ
- –ú–µ—Ç—Ä–∏–∫–∏: views, likes, shares, comments, favorites
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: –æ–ø–∏—Å–∞–Ω–∏–µ, —Ö–µ—à—Ç–µ–≥–∏, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –¥–∞—Ç–∞

**–ü–æ—á–µ–º—É –∏–¥–µ–∞–ª–µ–Ω:**
- ‚úÖ –†–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–∏—Ä—É—Å–Ω–æ—Å—Ç–∏
- ‚úÖ –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (–≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ TikTok)
- ‚úÖ –ë–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è fine-tuning)
- ‚úÖ –ì–æ—Ç–æ–≤—ã–µ labels –º–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å –∏–∑ engagement –º–µ—Ç—Ä–∏–∫

### 2. FineVideo (–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π)

**HuggingFace:** `HuggingFaceFV/finevideo`

**–°–æ–¥–µ—Ä–∂–∏—Ç:**
- 43,751 YouTube –≤–∏–¥–µ–æ (3,425 —á–∞—Å–æ–≤)
- –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏: mood, storytelling, scenes, QA
- 122 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**
- –î–æ–æ–±—É—á–µ–Ω–∏–µ VideoLLaMA3 –Ω–∞ understanding —Å—é–∂–µ—Ç–∞ –∏ —ç–º–æ—Ü–∏–π
- –ù–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ—Ç—Ä–∏–∫ –≤–∏—Ä—É—Å–Ω–æ—Å—Ç–∏, –Ω–æ —É—á–∏—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å content

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

```bash
cd /home/rustam/Projects/shorts-farm-n8n/virality-prediction

# –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–∫—Ä–∏–ø—Ç–æ–≤
mkdir -p scripts
chmod +x scripts/prepare_tiktok_dataset.py

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞ (100K –≤–∏–¥–µ–æ)
python scripts/prepare_tiktok_dataset.py \
    --output-dir ./data/tiktok_viral \
    --num-samples 100000 \
    --viral-ratio 0.3
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç —Å–∫—Ä–∏–ø—Ç:**
1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç TikTok-10M —Å HuggingFace
2. –§–∏–ª—å—Ç—Ä—É–µ—Ç –≤–∏–¥–µ–æ:
   - –ú–∏–Ω–∏–º—É–º 1K views (—É–±–∏—Ä–∞–µ—Ç —Å–ø–∞–º)
   - –ú–∞–∫—Å–∏–º—É–º 180 —Å–µ–∫—É–Ω–¥ (—Ñ–æ–∫—É—Å –Ω–∞ shorts)
   - –ï—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ (quality signal)
3. –í—ã—á–∏—Å–ª—è–µ—Ç virality –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–æ—Ä–º—É–ª—ã:
   ```
   engagement_rate = (likes + shares*3 + comments*2) / views
   is_viral = (engagement_rate > 5%) OR (views > 1M)
   ```
4. –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç (30% viral, 70% non-viral)
5. –î–µ–ª–∏—Ç –Ω–∞ train/val/test (80%/10%/10%)
6. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ CSV –∏ JSON

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```
data/tiktok_viral/
‚îú‚îÄ‚îÄ train.csv       # 80K –≤–∏–¥–µ–æ —Å labels
‚îú‚îÄ‚îÄ train.json
‚îú‚îÄ‚îÄ val.csv         # 10K –≤–∏–¥–µ–æ
‚îú‚îÄ‚îÄ val.json
‚îú‚îÄ‚îÄ test.csv        # 10K –≤–∏–¥eo
‚îú‚îÄ‚îÄ test.json
‚îî‚îÄ‚îÄ stats.json      # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
```

### –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

TikTok-10M —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, –Ω–µ —Å–∞–º–∏ –≤–∏–¥–µ–æ. –î–ª—è fine-tuning –Ω—É–∂–Ω–æ:

**–í–∞—Ä–∏–∞–Ω—Ç –ê: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å video embeddings (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)**
```python
# –ò—Å–ø–æ–ª—å–∑—É–µ–º pre-extracted features –∏–∑ TikTok-10M
# –ú–Ω–æ–≥–∏–µ –≤–∏–¥–µ–æ —É–∂–µ –∏–º–µ—é—Ç embeddings
```

**–í–∞—Ä–∏–∞–Ω—Ç –ë: –°–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ –ø–æ ID**
```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TikTok API –∏–ª–∏ scraper
# (—Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á –∏–ª–∏ –ø—Ä–æ–∫—Å–∏)
```

**–í–∞—Ä–∏–∞–Ω—Ç –í: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ**
```python
# –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ö–æ–∂–∏–µ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é Stable Video Diffusion
# –ò–ª–∏ augment —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤–∏–¥–µ–æ –∏–∑ UCF-101/Kinetics
```

### –®–∞–≥ 3: Fine-tuning VideoMAE

–°–æ–∑–¥–∞–π—Ç–µ `scripts/finetune_videomae.py`:

```python
from transformers import VideoMAEForVideoClassification, VideoMAEImageProcessor, Trainer, TrainingArguments
from datasets import load_dataset
import torch

# –ó–∞–≥—Ä—É–∑–∫–∞ prepared dataset
dataset = load_dataset("json", data_files={
    "train": "data/tiktok_viral/train.json",
    "val": "data/tiktok_viral/val.json",
    "test": "data/tiktok_viral/test.json"
})

# –ó–∞–≥—Ä—É–∑–∫–∞ pre-trained VideoMAE
model = VideoMAEForVideoClassification.from_pretrained(
    "MCG-NJU/videomae-base-finetuned-kinetics",
    num_labels=2,  # Binary: viral vs non-viral
    ignore_mismatched_sizes=True  # –ó–∞–º–µ–Ω—è–µ–º classifier head
)

processor = VideoMAEImageProcessor.from_pretrained("MCG-NJU/videomae-base-finetuned-kinetics")

# Training arguments
training_args = TrainingArguments(
    output_dir="./models/videomae-tiktok-viral",
    num_train_epochs=10,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=8,
    learning_rate=1e-4,
    weight_decay=0.01,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    fp16=True,  # Mixed precision –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
    logging_dir="./logs",
    logging_steps=100,
    warmup_steps=500,
)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["val"],
    compute_metrics=compute_metrics,  # Define your metrics
)

# Train!
trainer.train()

# Evaluate
results = trainer.evaluate(dataset["test"])
print(f"Test Accuracy: {results['eval_accuracy']:.2%}")

# Save model
model.save_pretrained("./models/videomae-tiktok-viral-final")
```

**–ó–∞–ø—É—Å–∫:**
```bash
python scripts/finetune_videomae.py
```

**–û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è:**
- –ù–∞ GPU 12GB: ~5-7 –¥–Ω–µ–π
- –ù–∞ GPU 24GB: ~2-3 –¥–Ω—è

**–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
- Baseline (–±–µ–∑ fine-tuning): ~65% accuracy
- –ü–æ—Å–ª–µ fine-tuning: ~85-90% accuracy

### –®–∞–≥ 4: Fine-tuning VideoLLaMA3 (Advanced)

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- GPU 24GB+ (–∏–ª–∏ multi-GPU)
- Parameter-Efficient Fine-Tuning (LoRA/QLoRA)

```python
from transformers import AutoModelForCausalLM, AutoProcessor, Trainer
from peft import LoraConfig, get_peft_model

# –ó–∞–≥—Ä—É–∑–∫–∞ VideoLLaMA3-2B
model = AutoModelForCausalLM.from_pretrained(
    "DAMO-NLP-SG/VideoLLaMA3-2B",
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

# LoRA config (—ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å)
lora_config = LoraConfig(
    r=16,  # LoRA rank
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM"
)

# –ü—Ä–∏–º–µ–Ω—è–µ–º LoRA
model = get_peft_model(model, lora_config)

# Training —Å instruction tuning
# –ü—Ä–æ–º–ø—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∞:
# "Analyze this TikTok video with {views} views and {engagement_rate}% engagement.
#  Explain why it is {viral/non-viral}."
```

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏

### –î–ª—è VideoMAE (Classification):

```python
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)

    accuracy = accuracy_score(labels, preds)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    auc = roc_auc_score(labels, pred.predictions[:, 1])

    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': auc
    }
```

**–¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:**
- Accuracy: >85%
- F1-score: >0.80
- AUC-ROC: >0.90

### –î–ª—è VideoLLaMA3 (Generation):

- BLEU/ROUGE –¥–ª—è quality reasoning
- Human evaluation –¥–ª—è usefulness
- Correlation —Å actual virality (Pearson's r)

## üéõÔ∏è –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã

### VideoMAE Fine-tuning:

```python
# –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è 12GB GPU
TrainingArguments(
    num_train_epochs=10,              # 10-20 epochs –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
    per_device_train_batch_size=4,    # 4-8 –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç VRAM
    learning_rate=1e-4,                # 1e-4 –¥–æ 1e-5
    weight_decay=0.01,                 # L2 regularization
    warmup_steps=500,                  # Gradual lr warmup
    fp16=True,                         # Mixed precision
    gradient_accumulation_steps=4,     # Effective batch size = 16
    max_grad_norm=1.0,                 # Gradient clipping
)
```

**Freezing strategy:**
```python
# Freeze backbone, train —Ç–æ–ª—å–∫–æ classifier
for name, param in model.named_parameters():
    if "classifier" not in name:
        param.requires_grad = False
```

### VideoLLaMA3 LoRA:

```python
LoraConfig(
    r=16,                # LoRA rank (8-32)
    lora_alpha=32,       # Scaling factor
    lora_dropout=0.1,    # Dropout –¥–ª—è regularization
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"]
)
```

## üí° Tips –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### 1. Data Augmentation

```python
# –î–ª—è –≤–∏–¥–µ–æ:
- Random crop
- Color jitter
- Temporal crop (—Ä–∞–∑–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—Ç—Ä–µ–∑–∫–∏)
- Speed augmentation (0.8x - 1.2x)
```

### 2. Class Balancing

```python
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ weighted loss –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
class_weights = torch.tensor([1.0, 2.0])  # –ë–æ–ª—å—à–µ –≤–µ—Å –¥–ª—è viral –∫–ª–∞—Å—Å–∞
criterion = nn.CrossEntropyLoss(weight=class_weights)
```

### 3. Transfer Learning Pipeline

```
UCF-101 (action recognition)
    ‚Üì
Kinetics-400 (pre-training)
    ‚Üì
TikTok-10M (fine-tuning)
    ‚Üì
Your specific domain
```

### 4. Ensemble Models

```python
# Combine predictions from multiple models
final_score = (
    videomae_score * 0.4 +
    videollama3_score * 0.6
)
```

## üêõ Troubleshooting

### OOM (Out of Memory)

**–†–µ—à–µ–Ω–∏—è:**
- –£–º–µ–Ω—å—à–∏—Ç—å batch size
- –í–∫–ª—é—á–∏—Ç—å gradient checkpointing
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å gradient accumulation
- Freeze –±–æ–ª—å—à–µ layers

```python
# Gradient checkpointing (—ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å)
model.gradient_checkpointing_enable()
```

### Overfitting

**–ü—Ä–∏–∑–Ω–∞–∫–∏:**
- Train accuracy >> Val accuracy
- Loss –Ω–∞ train –ø–∞–¥–∞–µ—Ç, –Ω–∞ val —Ä–∞—Å—Ç—ë—Ç

**–†–µ—à–µ–Ω–∏—è:**
- –£–≤–µ–ª–∏—á–∏—Ç—å dropout (0.1 ‚Üí 0.3)
- Stronger data augmentation
- Early stopping
- –ú–µ–Ω—å—à–µ epochs

### Underfitting

**–ü—Ä–∏–∑–Ω–∞–∫–∏:**
- Low accuracy –Ω–∞ train –∏ val
- Loss –Ω–µ –ø–∞–¥–∞–µ—Ç

**–†–µ—à–µ–Ω–∏—è:**
- –ë–æ–ª—å—à–µ epochs
- –í—ã—à–µ learning rate
- Unfreeze –±–æ–ª—å—à–µ layers
- Bigger model (2B ‚Üí 7B)

## üìö –†–µ—Å—É—Ä—Å—ã

### Papers:
- VideoMAE: https://arxiv.org/abs/2203.12602
- VideoLLaMA3: https://arxiv.org/abs/2501.13106
- LoRA: https://arxiv.org/abs/2106.09685

### Datasets:
- TikTok-10M: https://huggingface.co/datasets/The-data-company/TikTok-10M
- FineVideo: https://huggingface.co/datasets/HuggingFaceFV/finevideo
- UCF-101: https://huggingface.co/datasets/flwrlabs/ucf101

### Models:
- VideoMAE: https://huggingface.co/MCG-NJU/videomae-base-finetuned-kinetics
- VideoLLaMA3-2B: https://huggingface.co/DAMO-NLP-SG/VideoLLaMA3-2B

## üö¶ Roadmap

### Phase 1: Quick Win (1-2 –Ω–µ–¥–µ–ª–∏)
- ‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å TikTok-10M –¥–∞—Ç–∞—Å–µ—Ç
- ‚úÖ Fine-tune VideoMAE –Ω–∞ 100K –≤–∏–¥–µ–æ
- ‚úÖ Evaluate –∏ deploy

**–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:** +15-20% accuracy

### Phase 2: Advanced (1 –º–µ—Å—è—Ü)
- Fine-tune VideoLLaMA3 —Å LoRA
- –î–æ–±–∞–≤–∏—Ç—å FineVideo –¥–ª—è reasoning
- Ensemble VideoMAE + VideoLLaMA3

**–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:** +25-30% accuracy

### Phase 3: Production (2-3 –º–µ—Å—è—Ü–∞)
- Collect —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ viral TikTok –¥–∞–Ω–Ω—ã–µ
- Continuous learning pipeline
- A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- Monitor drift –∏ retrain

**–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:** +35-40% accuracy

## ‚ö° –ò—Ç–æ–≥–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è

**–ù–∞—á–Ω–∏—Ç–µ —Å TikTok-10M + VideoMAE:**
1. –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å –∫ —É–ª—É—á—à–µ–Ω–∏—é
2. –¢—Ä–µ–±—É–µ—Ç —Ç–æ–ª—å–∫–æ 12GB GPU
3. –ú–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å –∑–∞ –Ω–µ–¥–µ–ª—é
4. Immediate impact –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å

**–ó–∞—Ç–µ–º –¥–æ–±–∞–≤—å—Ç–µ VideoLLaMA3:**
- –î–ª—è –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ reasoning
- –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤

**–í –±—É–¥—É—â–µ–º:**
- –°–æ–±–µ—Ä–∏—Ç–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ –≤–∞—à–µ–≥–æ production traffic
- Continuous learning –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- Custom –º–æ–¥–µ–ª—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –ø–æ–¥ –≤–∞—à–∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –≤–∏—Ä—É—Å–Ω–æ—Å—Ç–∏
